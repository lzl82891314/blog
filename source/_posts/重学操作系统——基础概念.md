---
title: 重学操作系统——基础概念
url_name: os-basics
date: 2021-09-20 08:35:01
categories:
  - 操作系统
tags:
  - 操作系统
  - 基础知识
---

很久没有写笔记了，着实是对之前的工作没有爱，真写不了 WPF 的东西，而最近的工作中却遇到了几个让我头大的事，让我发现自己的操作系统真的丢在了大学期末考试的考场上。书到用时方恨少，遇到问了才发现很多问题自己根本没法理解。痛定思痛，我决定还是从头再学一次操作系统吧。

<!-- more -->

## 写在前面

所以还是先说一下之前碰到的几个让人蛋疼的事吧。

### 一、为啥都是说 Golang 中的并发代价很小？

最近一直都在学 Golang，本来打算学完之后写一篇关于 Golang 入门的笔记，结果越学越不会，完全达不到给同事做培训的程度，主要原因是很多东西都不经问，一问我可能真的三不知…

比如 Golang 最拿得出手的其实就是并发处理能力，其内部的 goroutine 能轻而易举的创建几万个，相比于 C#，都说 Golang 的协程更轻量。然而到底为什么能比普通线程的资源占比低，我却看得云里雾里，网上搜到的解释，要么看不懂，要么看完就忘…

而这时候我才发现，自己连线程基本的概念都不了解，什么 TCP 完全对我来说就是陌生人，更别说线程创建的资源消耗在哪这种问题了。

### 二、啥是 CPU 密集型啥又是 IO 密集型？

上周和一个同事争论了一番 C#中 Task 的概念，我之前一直以为，C#中的 Task 其实就是封装了线程的语法糖，只要 Run 一个 Task 背后就是新创建了一个线程。结果被同事发来一篇 [There Is No Thread](https://blog.stephencleary.com/2013/11/there-is-no-thread.html) 怼的哑口无言，到这里我才知道多线程 CPU 密集型和 IO 密集型的区别，也才知道 IO 操作并不会占用 CPU 资源，是通过系统中断实现的…

此外，最近也在之湖上看到了这个问题[async/await 异步模型是否优于 stackful coroutine 模型？](https://www.zhihu.com/question/65647171)，感觉里面的解答说的都是头头是道，我就像个傻子只会拍手凑热闹。或许操作系统学完我该好好补补 C#的 TAP 了，“会用就行”这种浮躁的心态早晚还能闹出更多洋相的。

### 三、虚拟内存分页大小为啥能解决 Not enough quota 问题？

这两周我的 WPF 项目在启动时，总是报 `Not enough quota is available to process this command` 异常，而且有点离谱的是第一次启动报异常，第二次就好了，第三次异常第四次又好了…好家伙，还和奇偶性有关。

网上搜到的解答，都是说我的虚拟内存分页文件太小导致的，而我跟着教程一步步将自动管理的分页文件大小调大之后，好家伙，奇偶性问题变成必发问题彻底不能用了…

其实这个问题我还是研究了一下的，因为大家的设备都一样，为啥就我的启动会报错？带着这个问题找区别，我发现只有我一直在用 Wallpaper Engine，关了之后瞬间问题就解决了。查了一下发现 Wallpaper Engine 的实现原理就是调用了 win32 的一个 dll，在桌面的背后又创建了一个桌面盖在了桌面的后面，其实就是一个 window。而好巧不巧 WPF 启动加载资源报错的正好就是 win32 的那个 dll。所以初步看应该 Wallpaper Engine 把 win32 的 dll 的 quota 耗尽了？

虽然问题是基本解决了，但是查问题时碰到的啥是虚拟内存？啥是分页大小？啥又是分页文件？完全一窍不通…

哎，带着上面三个问题，最终还是打算中断 Golang 的学习，先补补操作系统的课，希望全部笔记写完之后我能很轻松的说出上面三个问题的根本原因。

### 学习资料

工欲善其事必先利其器，我不是一个擅长看书学习的人，可能自己有一点点的阅读障碍症，所以我还是习惯于通过视频学习。为此，我找到了以下的几个很不错的操作系统学习资料（这里感谢 B 站的大数据帮我自动推送出清华大学的公开课）：

- [【清华大学】操作系统 陈渝](https://www.bilibili.com/video/BV1wW41117GS)
- [王道计算机考研 操作系统](https://www.bilibili.com/video/BV1YE411D7nH)
- [CS-Notes](https://github.com/CyC2018/CS-Notes)
- [学堂在线-操作系统](https://www.xuetangx.com/learn/THU08091000267/THU08091000267/7753473/video/12680087)

学习方法是：以清华公开课为主（这门课讲的是真的好，听起来一点睡意都没有），王道考研补充零散知识点（虽然课讲的不太行，但是笔记脑图整理的非常好，非常适合拿来主义），Cs-Notes 做笔记大纲。

后面又补充了学堂在线的操作系统课程，这个课是清华大学公开课的后续升级版本，又加入了这个课的主要原因是现在 B 站所有清华操作系统公开课都缺少 7.12 这一节，为了知道这节讲的是什么，后面又学习了学堂在线的课程。

## 发展史

我一直再说的观点就是知识不应该只去记零散的点，而是应该从头到尾形成一条记忆链，这样才不容易遗忘。之前写云技术那篇 Blog 时，就是以这样的形式从无到有学习的。同样，发展史记录了操作系统的初始和演进，是一个知识体系的头结点，所以应该去学习。

### 手工操作阶段

操作系统其实是和计算机共同发展的，在这个阶段还没有操作系统，计算机都是需要纸带进行输入输出的巨型设备，那个时期操作计算机的不应该叫程序员应该叫操作员，他们的任务是把记录程序的纸带输入到计算机中，当计算机执行结束后再将结束同样输出到纸带中。

![computer-by-manual](https://image.dunbreak.cn/os/computer-by-manual.png)

### 批处理阶段

这个阶段开始，操作系统的概念开始逐步诞生。在这个阶段初期，人们为了解决上述的速度矛盾，将多个单一的纸带合并为了一个磁带，并且将磁带输入计算机，之后在输出。这时的系统被称为`单道批处理系统`，这个时期操作系统刚诞生，但是它当时主要的任务是协助计算机正确加载磁带。

这之后，进入了`多道批处理阶段`。这个阶段人们发现，很多任务其实是可以并发执行的，即输入和输出数据时，CPU 其实是空闲，那么有没有可能，在第一个任务执行的同时输入第二个程序，在第一个程序执行结束后 CPU 可以无缝衔接第二个程序继续执行，并且并不会影响第一个程序的输出。

在这个阶段有两个主要的操作系统特征出现，一个是`中断`一个是`并发`。当有输入设备进行输入时，正在执行中的操作系统需要通过中断发起 IO 操作，并且 IO 和执行程序是在同一个时间段内发生的，这个特征就是并发，这两个特征后面会详细说明。

以下有一个例子可以很好地说明单道批处理和多道批处理之间的性能差异。

如果同时执行三个需要 1 秒完成读写执行的任务，在单道批处理阶段，我们可以看到完成这三个作业需要 9 秒：

![batch-handle-01](https://image.dunbreak.cn/os/batch-handle-01.png)

而同样的作业如果在多道批处理系统中执行，由于`并发`的产生，时间会缩短到 5 秒：

![batch-handle-02](https://image.dunbreak.cn/os/batch-handle-02.png)

### 分时系统

批处理系统虽然有效的提高了 CPU 利用率太低的问题，但是人际交互的能力很差，因为它并不能将程序全部输入计算机，必须一个执行结束再输入第二个，因此人们希望计算机能够同时执行多个任务，这也就是分时系统。

在此系统中，CPU 资源会被切分成很小的时间片比如 1ms，然后依次分为计算机内所有需要执行的程序。由于人感知不到这么短的时间，所以对人来说，这些程序就是在并发执行的。需要说明一点是，操作系统是由时钟外设记录时间并且触发中断进行程序切换的。

### 实时系统

分时系统已经很好地利用系统资源并且提供了很好的人机交互能力了，但是它并不能提供任务优先级的能力，因为并不是说计算机内的每个程序都是同等优先级的，有的任务需要立刻执行完毕，有的任务却没那么重要。为了满足这个需求，就有了实时操作系统。

其核心应该是利用多级反馈队列算法管理进程，对进程的优先级进行分级进行处理。并且实时系统还分为硬实时系统，比如导弹系统，自动驾驶系统等这些必须在规定时间内完成的系统；还有软实时即尽量在特定时间完成任务的系统。

同时，也是这个阶段，由于 CPU 和硬件的价格持续下降，计算机进入了 PC 时代。当然除了 PC 系统之外还有网络系统，分布式系统等，但这些系统没有演进操作系统的概念，因此就不单独说了。

最后，可以通过下图来简单了解操作系统的进化史：

![os-development](https://image.dunbreak.cn/os/os-development.png)

## 基本特征

从发展史中我们可以看出，操作系统是随着需求的变化逐步发展的，并且最终出现了以下四个基本的特征。

> 操作系统启动流程：CPU 加电 --> 运行主板中的 BIOS 中的程序 --> BIOS 中的程序加载硬盘中的引导扇区 --> 引导扇区启动 BootLoader 程序 (只有 512 个字节) --> BootLoader 找到操作系统存储的扇区并且将操作系统从硬盘中加载到内存中运行

### 并发

并发就是我们工作中所说的并发，即`一个时间段内`存在多个程序共同执行

此概念区别于`并行 Parallel`，并行是在`一个时刻`同时有两个程序执行，单核 CPU 是无法实现并行的，但是可以实现并发，其原理就是时间片轮转

### 共享

共享就是资源共享，主要分两种，互斥共享和同时共享。

1. 互斥共享推进了锁、信号量、管程等技术的出现，主要是通过这些技术实现一个时间段内只有一个程序访问共享资源
2. 同时共享就是字面意思，一个资源在同一时刻可以由多个程序共同使用，比如边玩游戏边听歌，扬声器同时会播放两种音乐，这里扬声器就是同时共享资源

### 虚拟

这里所说的虚拟和虚拟化技术不是一个概念。主要分两个部分，`时分复用`和`空分复用`，这里的时空就是算法概念下的`时间`和`空间`。

1. 时分复用是将 CPU 资源进行拆分，让每个程序轮流使用，每次执行一小段时间比如 50ms，并且会快速切换，让人感觉程序就是在并行执行的
2. 空分复用技术就是虚拟内存技术，操作系统将硬盘等外部存储虚拟化为虚拟内存，在程序执行时进行页面置换操作，使得 8G 的内存也可以同时运行超过 8G 的程序，其核心原理是`局部性原理`（内存管理的重点，后续的 blog 中会说明）

### 异步

这里的异步和编程中说到的异步也不是一个概念，而是说操作系统中的程序不是一步到位执行结束的，而是依赖于虚拟技术轮流执行一段，走走停停地向前推进

## 内核状态

### 什么是内核

内核其实就是计算机最底层的软件，是操作系统的核心功能。这写程序都是计算机能正常运行必须要有的程序，主要可以分一下几类：

![kernel-categories](https://image.dunbreak.cn/os/kernel-categories.png)

以 Linux 为例，Linux 其实可以分为 Kernel 和 Shell，其中 Kernel 就是系统内核程序，而我们操作输入指令的 Shell 其实就是一个命令解释器，它解析操作系统为各个指令封装好的 API 提供给 Kernel 运行。

> 一个小插曲，我之前一直不知道 Shell 和 Bash 的区别是啥，其实它们都是 Shell 程序，而 Shell 这个概念在 Unix 诞生之前就出现了，之后 Unix 的 Shell 维护者叫 Brian J. Fox，他在为 Unix 编写 Shell 时一语双关将 Bourne shell 改为了 Bash，意为 Bourne-Again Shell

而操作系统内核也是分为为内核和大内核两类的，其中微内核就是仅把必须要写在内核中的程序划分为内核程序，其余的程序都放在了用户态，其好处就是内核轻便易于维护，而缺点是性能差，因为需要大量的系统调用使用户态和内核态交互。

而大内核正好与此相反，其区别可以在下图中看到：

![os-structure](https://image.dunbreak.cn/os/os-structure.png)

### 用户态 和 内核态

之前看 Golang 说协程的时候，总是提到什么内核态用户态的概念，当时看的是云里雾里，其实这里说的`内核态`和`用户态`其实是 CPU 指令集的状态。

我们知道，CPU 其实执行的一条一条的指令，一个 C 语言的语句被编译后会变成汇编语言，一条汇编语言就对应着一个 CPU 指令。多个指令组合在一起，会形成一个指令集，硬件设备商为这些指令集进行了权限划分，以 Inter 为例，CPU 指令集被分为 ring 0 ~ ring3 一共 4 个级别。其中 ring 0 是最高权限级别，可以操作所有的 CPU 指令集，Linux 系统采用 ring 0 和 ring3 两个权限。综上，对于 Linux 来说，ring 0 就是内核态， ring 3 就是用户态。

我们自己写的程序都是运行在用户态的，无法获取到内核态的指令，只有操作系统有权限调用内核指令。

这样拆分的主要目的是为了安全性，因为操作系统是计算机唯一能完全信任的程序，用户编写的程序都是不可信的，不能让其轻易获得内核态的指令，为此人为的加入了内核态和用户态的限制。

但是这些切分是有代价的，因为用户态和内核态都需要维护一套内存、堆栈寄存器、句柄等资源，之间是无法共享的。当程序由用户态切换到内核态时，会发生内存拷贝，并且内核态的程序运行结束后，如果有返回，依然是发生内存拷贝，其代价是很大的。也就因此有了这个面试问题：[阿里二面：什么是 mmap？](https://mp.weixin.qq.com/s/sG0rviJlhVtHzGfd5NoqDQ)

## 交互

上面说了我们写的代码只能执行在用户态，那么像把 Hello World 输出到屏幕上这样的程序应该如何执行呢？这就引出了程序和系统的交互问题。

用户态的程序只有三个途径可以和内核交互，即`系统调用`、`中断`以及`异常`。

### 系统调用

系统调用是用户态的程序在执行中，需要对内核指令进行操作时向操作系统发起的，上述说到的输出字符串到屏幕就需要用户程序发一起一个操作屏幕输出的系统调用。

上一节也说过了，系统调用需要进程上下文从用户态切换到内核态，其需要拷贝内存堆栈句柄寄存器等一系列资源，是有开销的，但是与安全性相比，这些开销是必要的。

系统调用可以同步或异步地`由用户态进程发出`。

### 中断 和 异常

中断也分为外中断和内中断，内中断就是指`异常`，其处理逻辑都是相同的，只不过`由用户态发起`的中断是外中断，由`CPU 执行指令的内部事件引起触发`的中断是异常。

当用户态程序执行中触发系统中断时，操作系统会把正在运行程序的资源进行临时记录，从而去执行中断程序，当中断程序执行结束后，操作系统会通过之前记录的资源还原回中断之前的状态，继续执行之前的程序。

举一个可以很好描述中断的例子：我们可以把正在执行的程序看做是一个正在做饭的厨师，他正在按照菜谱（程序）做饭，这时，他的儿子突然进来告诉他自己的手被蜜蜂咬了。那么这个厨师只能先停下手头的工作（系统中断），去拿家里的医药箱给儿子上药。上完药之后，他就继续回去做饭。

此外，系统中断和系统调用都会有对应的编号，以系统中断举例：系统中断由硬件和操作系统协同配合完成，其中系统中断是由硬件发起的，硬件会像系统设置一个中断标记，CPU 读取到对应的标记后，会从操作系统内建的中断表中查找对应的中断号，从而进一步执行系统中断。当 CPU 执行中断时，原本的应用会被暂停，应用中的数据会被操作系统记录在寄存器中，当系统中断执行结束后，操作系统还需要取出寄存器的数据将其还原回去。

## 记忆链

1. 为了安全性考虑，一般 CPU 指令集会被划分权限。故而操作系统将低权限定义为用户态，供用户程序调用；高权限定义为内核态，是计算机运行不可或缺的底层功能
2. 用户的程序和内核态交互的唯三途径是：系统调用，中断和异常
3. 用户进程系统调用会进行资源拷贝，会将用户态的资源拷贝一份到内核态，当内核态程序调用结束需要输出时，同样要将其拷贝至用户态，主要有内存、句柄和寄存器
4. 中断和异常都可以称为中断，其处理逻辑基本相同，区别是触发源不同，外中断来自用户态，内中断即异常来自 CPU 内部事件
